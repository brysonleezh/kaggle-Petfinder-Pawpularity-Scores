{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T15:43:42.422889Z",
     "iopub.status.busy": "2022-01-09T15:43:42.422581Z",
     "iopub.status.idle": "2022-01-09T15:43:49.630158Z",
     "shell.execute_reply": "2022-01-09T15:43:49.629345Z",
     "shell.execute_reply.started": "2022-01-09T15:43:42.422807Z"
    }
   },
   "source": [
    "<h4>Explanation</h4>\n",
    "\n",
    "Path Setup: Adds the path to the timm library, which contains pre-trained image models.\n",
    "\n",
    "Imports: Imports necessary libraries and functions from timm and fastai.vision.all.\n",
    "\n",
    "Seed Setting: Sets a seed (999) for reproducibility to ensure consistent results.\n",
    "\n",
    "Batch Size and Model Configuration: Configures the batch size (32) and specifies the model (swin_large_patch4_window12_384_in22k) and image size (224).\n",
    "\n",
    "Garbage Collection: Imports the gc module for potential memory management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "\n",
    "# Add the path to the timm library for image models\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "# Import the necessary modules\n",
    "from timm import create_model\n",
    "from fastai.vision.all import *\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "myseed = 999\n",
    "set_seed(myseed, reproducible=True)\n",
    "\n",
    "# Define the batch size and model parameters\n",
    "BATCH_SIZE = 32\n",
    "model_name = 'swin_large_patch4_window12_384_in22k'\n",
    "image_size = 224\n",
    "\n",
    "# Optional: garbage collection for memory management\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path Setup: Defines the path to the dataset.\n",
    "\n",
    "Data Loading: Loads the training data from a CSV file into a DataFrame.\n",
    "\n",
    "Image Path Creation: Maps the image file paths to a new column in the DataFrame.\n",
    "\n",
    "DataFrame Update: Drops the 'Id' column from the DataFrame.\n",
    "\n",
    "Shuffling: Shuffles the DataFrame to ensure random order.\n",
    "\n",
    "DataFrame Length: Prints the number of images in the dataset.\n",
    "\n",
    "Normalization: Normalizes the Pawpularity score by dividing by 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = Path('../input/petfinder-pawpularity-score/')\n",
    "\n",
    "# Load the training data\n",
    "train_df = pd.read_csv(dataset_path / 'train.csv')\n",
    "\n",
    "# Create the image paths and update the DataFrame\n",
    "train_df['path'] = train_df['Id'].map(lambda x: str(dataset_path / 'train' / x) + '.jpg')\n",
    "train_df = train_df.drop(columns=['Id'])\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Get the length of the DataFrame\n",
    "len_df = len(train_df)\n",
    "print(f\"There are {len_df} images\")\n",
    "\n",
    "# Normalize the Pawpularity score\n",
    "train_df['norm_score'] = train_df['Pawpularity'] / 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Ensure the checkpoint directory exists\n",
    "checkpoint_dir = '/root/.cache/torch/hub/checkpoints/'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Copy the pre-trained model checkpoint to the required location\n",
    "os.system(\"cp '../input/swin-transformer/swin_large_patch4_window7_224_22kto1k.pth' '/root/.cache/torch/hub/checkpoints/swin_large_patch4_window7_224_22kto1k.pth'\")\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 999\n",
    "set_seed(seed, reproducible=True)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Sturges' rule\n",
    "num_bins = int(np.floor(1+(3.3)*(np.log2(len(train_df)))))\n",
    "# num_bins = int(np.ceil(2*((len(train_df))**(1./3))))\n",
    "train_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T14:48:50.525278Z",
     "iopub.status.busy": "2022-01-09T14:48:50.524705Z",
     "iopub.status.idle": "2022-01-09T14:48:50.87805Z",
     "shell.execute_reply": "2022-01-09T14:48:50.877313Z",
     "shell.execute_reply.started": "2022-01-09T14:48:50.525238Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "train_df['fold'] = -1\n",
    "\n",
    "\n",
    "N_FOLDS = 5\n",
    "strat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\n",
    "for i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n",
    "    train_df.iloc[train_index, -1] = i\n",
    "    \n",
    "train_df['fold'] = train_df['fold'].astype('int')\n",
    "\n",
    "train_df.fold.value_counts().plot.bar()\n",
    "train_df.to_csv('df_train_fold_struggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T14:48:50.879863Z",
     "iopub.status.busy": "2022-01-09T14:48:50.87942Z",
     "iopub.status.idle": "2022-01-09T14:48:55.883062Z",
     "shell.execute_reply": "2022-01-09T14:48:55.882285Z",
     "shell.execute_reply.started": "2022-01-09T14:48:50.879826Z"
    }
   },
   "outputs": [],
   "source": [
    "def petfinder_rmse(input,target):\n",
    "    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n",
    "\n",
    "def get_data(fold):\n",
    "#     train_df_no_val = train_df.query(f'fold != {fold}')\n",
    "#     train_df_val = train_df.query(f'fold == {fold}')\n",
    "    \n",
    "#     train_df_bal = pd.concat([train_df_no_val,train_df_val.sample(frac=1).reset_index(drop=True)])\n",
    "    train_df_f = train_df.copy()\n",
    "    # add is_valid for validation fold\n",
    "    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n",
    "    \n",
    "    dls = ImageDataLoaders.from_df(train_df_f, #pass in train DataFrame\n",
    "#                                valid_pct=0.2, #80-20 train-validation random split\n",
    "                               valid_col='is_valid', #\n",
    "                               seed=myseed , #seed\n",
    "                               fn_col='path', #filename/path is in the second column of the DataFrame\n",
    "                               label_col='norm_score', #label is in the first column of the DataFrame\n",
    "                               y_block=RegressionBlock, #The type of target\n",
    "                               bs=BATCH_SIZE, #pass in batch size\n",
    "                               num_workers=8,\n",
    "                               item_tfms=Resize(image_size), #pass in item_tfms\n",
    "                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) #pass in batch_tfms\n",
    "    \n",
    "    return dls\n",
    "\n",
    "#Valid Kfolder size\n",
    "the_data = get_data(0)\n",
    "assert (len(the_data.train) + len(the_data.valid)) == (len(train_df)//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T14:48:55.884792Z",
     "iopub.status.busy": "2022-01-09T14:48:55.884491Z",
     "iopub.status.idle": "2022-01-09T14:48:55.891172Z",
     "shell.execute_reply": "2022-01-09T14:48:55.890496Z",
     "shell.execute_reply.started": "2022-01-09T14:48:55.884755Z"
    }
   },
   "outputs": [],
   "source": [
    "class cust_fastai_model(nn.Module):      \n",
    "    def __init__(self, model_name='swin_large_patch4_window7_224',ifpretrained=True):\n",
    "        super().__init__()\n",
    "        self.swin = create_model(model_name, pretrained=ifpretrained, num_classes=0)\n",
    "        self.custom_head = nn.Linear(in_features=1536, out_features=1, bias=True)\n",
    "        # self.custom_head = nn.Linear1,2,3; 2Ddropout; a conv layer? etc\n",
    "\n",
    "    def forward(self, image):\n",
    "        emb = self.swin(image).squeeze(-1).squeeze(-1)\n",
    "        out = self.custom_head(emb)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T14:48:55.894311Z",
     "iopub.status.busy": "2022-01-09T14:48:55.893862Z",
     "iopub.status.idle": "2022-01-09T14:48:58.369326Z",
     "shell.execute_reply": "2022-01-09T14:48:58.368502Z",
     "shell.execute_reply.started": "2022-01-09T14:48:55.894271Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_learner(fold_num,model_name='swin_large_patch4_window7_224',ifpretrained=True,ifcut=False):\n",
    "    data = get_data(fold_num)\n",
    "    if ifcut:\n",
    "        model = cust_fastai_model(model_name,ifpretrained)\n",
    "    else:\n",
    "        model = create_model(model_name, pretrained=ifpretrained, num_classes=data.c)\n",
    "    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse).to_fp16()\n",
    "    return learn\n",
    "\n",
    "test_df = pd.read_csv(dataset_path/'test.csv')\n",
    "test_df['Pawpularity'] = [1]*len(test_df)\n",
    "test_df['path'] = test_df['Id'].map(lambda x:str(dataset_path/'test'/x)+'.jpg')\n",
    "test_df = test_df.drop(columns=['Id'])\n",
    "train_df['norm_score'] = train_df['Pawpularity']/100\n",
    "\n",
    "# get_learner(fold_num=0).lr_find(end_lr=3e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T14:48:58.371787Z",
     "iopub.status.busy": "2022-01-09T14:48:58.371206Z",
     "iopub.status.idle": "2022-01-09T14:48:58.412994Z",
     "shell.execute_reply": "2022-01-09T14:48:58.412071Z",
     "shell.execute_reply.started": "2022-01-09T14:48:58.371745Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_submit(model_name,ifpretrained,image_size,model_path,n,beta,N_FOLDS=5,ifcut=False):\n",
    "    all_preds = []\n",
    "    for i in range(N_FOLDS):\n",
    "        print(f'Fold {i} results')\n",
    "        learn = get_learner(fold_num=i,model_name=model_name,ifpretrained=ifpretrained,ifcut=ifcut)\n",
    "        learn.model_dir = ''\n",
    "        learn.load(model_path + f'{i}.pkl')\n",
    "        dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n",
    "                                   valid_pct=0.2, #80-20 train-validation random split\n",
    "                                   seed=myseed , #seed\n",
    "                                   fn_col='path', #filename/path is in the second column of t|he DataFrame\n",
    "                                   label_col='norm_score', #label is in the first column of the DataFrame\n",
    "                                   y_block=RegressionBlock, #The type of target\n",
    "                                   bs=BATCH_SIZE, #pass in batch size\n",
    "                                   num_workers=8,\n",
    "                                   item_tfms=Resize(image_size), #pass in item_tfms\n",
    "                                   batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(),RandomErasing(p=0.5, max_count=6)])) \n",
    "\n",
    "        test_dl = dls.test_dl(test_df)\n",
    "        preds, _ = learn.tta(dl=test_dl, n=n, beta=beta)\n",
    "        all_preds.append(preds)\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    sample_df = pd.read_csv(dataset_path/'sample_submission.csv')\n",
    "    preds = np.mean(np.stack(all_preds), axis=0)\n",
    "    sample_df['Pawpularity'] = preds*100 \n",
    "    return sample_df\n",
    "\n",
    "\n",
    "def get_submit_load_learner():\n",
    "    all_preds = []\n",
    "    for i in range(N_FOLDS):\n",
    "        print(f'Fold {i} results')\n",
    "        learn = load_learner(f'../input/lovely-doggo-with-bonky-fastai-timm/model_fold_{i}.pkl')\n",
    "        dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n",
    "                                   valid_pct=0.2, #80-20 train-validation random split\n",
    "                                   seed=myseed , #seed\n",
    "                                   fn_col='path', #filename/path is in the second column of t|he DataFrame\n",
    "                                   label_col='norm_score', #label is in the first column of the DataFrame\n",
    "                                   y_block=RegressionBlock, #The type of target\n",
    "                                   bs=BATCH_SIZE, #pass in batch size\n",
    "                                   num_workers=8,\n",
    "                                   item_tfms=Resize(224), #pass in item_tfms\n",
    "                                   batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(),RandomErasing(p=0.5, max_count=6)])) \n",
    "\n",
    "        test_dl = dls.test_dl(test_df)\n",
    "        preds, _ = learn.tta(dl=test_dl, n=5, beta=0)\n",
    "        all_preds.append(preds)\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    sample_df = pd.read_csv(dataset_path/'sample_submission.csv')\n",
    "    preds = np.mean(np.stack(all_preds), axis=0)\n",
    "    sample_df['Pawpularity'] = preds*100 \n",
    "    return sample_df\n",
    "\n",
    "\n",
    "def test_cv(model_name,ifpretrained,image_size,model_path,n,beta,train_df,N_FOLDS=5,ifcut=False):\n",
    "    all_preds = []\n",
    "    train_df_f = train_df.copy()\n",
    "    train_df_f['pred'] = 1\n",
    "    for i in range(N_FOLDS):\n",
    "        learn = get_learner(fold_num=i,model_name=model_name,ifpretrained=ifpretrained,ifcut=ifcut)\n",
    "        learn.model_dir = ''\n",
    "        learn.load(model_path + f'{i}.pkl')\n",
    "        dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n",
    "                                   valid_pct=0.2, #80-20 train-validation random split\n",
    "                                   seed=999, #seed\n",
    "                                   fn_col='path', #filename/path is in the second column of t|he DataFrame\n",
    "                                   label_col='norm_score', #label is in the first column of the DataFrame\n",
    "                                   y_block=RegressionBlock, #The type of target\n",
    "                                   bs=BATCH_SIZE, #pass in batch size\n",
    "                                   num_workers=8,\n",
    "                                   item_tfms=Resize(image_size), #pass in item_tfms\n",
    "                                   batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(),RandomErasing(p=0.5, max_count=6)])) \n",
    "\n",
    "        test_dl = dls.test_dl(train_df[train_df['fold'] == i])\n",
    "        preds, _ = learn.tta(dl=test_dl, n=n, beta=beta)\n",
    "        preds = preds.view(preds.size(0),)\n",
    "        print(f'Fold {i} results' , np.sqrt(((np.array(preds) - train_df[train_df['fold'] == i]['norm_score'])**2).mean()))\n",
    "        train_df_f.loc[train_df_f['fold'] == i,'pred'] = np.array(preds)\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    print(np.sqrt(((train_df_f['pred'] - train_df_f['norm_score']) ** 2).mean()))\n",
    "    return train_df_f\n",
    "\n",
    "def test_cv(model_name,ifpretrained,image_size,model_path,n,beta,train_df,N_FOLDS=5,ifcut=False):\n",
    "    all_preds = []\n",
    "    train_df_f = train_df.copy()\n",
    "    train_df_f['pred'] = 1\n",
    "    for i in range(N_FOLDS):\n",
    "        learn = get_learner(fold_num=i,model_name=model_name,ifpretrained=ifpretrained,ifcut=ifcut)\n",
    "        learn.model_dir = ''\n",
    "        learn.load(model_path + f'{i}.pkl')\n",
    "        dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n",
    "                                   valid_pct=0.2, #80-20 train-validation random split\n",
    "                                   seed=999, #seed\n",
    "                                   fn_col='path', #filename/path is in the second column of t|he DataFrame\n",
    "                                   label_col='norm_score', #label is in the first column of the DataFrame\n",
    "                                   y_block=RegressionBlock, #The type of target\n",
    "                                   bs=BATCH_SIZE, #pass in batch size\n",
    "                                   num_workers=8,\n",
    "                                   item_tfms=Resize(image_size), #pass in item_tfms\n",
    "                                   batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(),RandomErasing(p=0.5, max_count=6)])) \n",
    "\n",
    "        test_dl = dls.test_dl(train_df[train_df['fold'] == i])\n",
    "        preds, _ = learn.tta(dl=test_dl, n=n, beta=beta)\n",
    "        preds = preds.view(preds.size(0),)\n",
    "        print(f'Fold {i} results' , np.sqrt(((np.array(preds) - train_df[train_df['fold'] == i]['norm_score'])**2).mean()))\n",
    "        train_df_f.loc[train_df_f['fold'] == i,'pred'] = np.array(preds)\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    print(np.sqrt(((train_df_f['pred'] - train_df_f['norm_score']) ** 2).mean()))\n",
    "    return train_df_f\n",
    "\n",
    "def train_svr(model_name,ifpretrained,image_size,model_path,n,beta,train_df,iftrain=True,N_FOLDS=5,ifcut=False,svr_name = 'name'):\n",
    "    all_preds = []\n",
    "    train_df_f = train_df.copy()\n",
    "\n",
    "    for i in range(N_FOLDS): \n",
    "        learn = get_learner(fold_num=i,model_name=model_name,ifpretrained=ifpretrained,ifcut=ifcut)\n",
    "        learn.model_dir = ''\n",
    "        learn.load(model_path + f'{i}.pkl')\n",
    "        learn.model.head = nn.Identity()\n",
    "        dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n",
    "                            valid_pct=0.2, #80-20 train-validation random split\n",
    "                            seed=myseed, #seed\n",
    "                            fn_col='path', #filename/path is in the second column of t|he DataFrame\n",
    "                            label_col='norm_score', #label is in the first column of the DataFrame\n",
    "                            y_block=RegressionBlock, #The type of target\n",
    "                            bs=BATCH_SIZE, #pass in batch size\n",
    "                            num_workers=8,\n",
    "                            item_tfms=Resize(image_size), #pass in item_tfms\n",
    "                            batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(),RandomErasing(p=0.5, max_count=6)])) \n",
    "\n",
    "        if iftrain:\n",
    "            train_dl = dls.test_dl(train_df[train_df['fold'] != i])\n",
    "            embed, _ = learn.tta(dl=train_dl, n=n, beta=beta)\n",
    "            embed = embed.numpy()\n",
    "            clf = SVR(C=20.0)\n",
    "            clf.fit(embed.astype('float32'), train_df[train_df['fold'] != i].Pawpularity.values.astype('int32'))\n",
    "            pickle.dump(clf, open('./' + svr_name + f'_{i}.pkl', \"wb\"))\n",
    "\n",
    "        else:\n",
    "            train_dl = dls.test_dl(train_df[train_df['fold'] == i])\n",
    "            embed, _ = learn.tta(dl=train_dl, n=n, beta=beta)\n",
    "            embed = embed.numpy()\n",
    "            clf = pickle.load(open('./' + svr_name + f'_{i}.pkl', \"rb\"))\n",
    "            pred_clf = clf.predict(embed)\n",
    "\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "def test_rmse(pred,target):\n",
    "    return np.sqrt(((np.array(pred) - np.array(target))**2).mean()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T14:48:58.414895Z",
     "iopub.status.busy": "2022-01-09T14:48:58.414462Z",
     "iopub.status.idle": "2022-01-09T14:49:01.277104Z",
     "shell.execute_reply": "2022-01-09T14:49:01.276336Z",
     "shell.execute_reply.started": "2022-01-09T14:48:58.414855Z"
    }
   },
   "outputs": [],
   "source": [
    "import cuml, pickle\n",
    "from cuml.svm import SVR\n",
    "\n",
    "def get_submit_svr(model_name,ifpretrained,image_size,model_path,n,beta,N_FOLDS=5,ifcut=False,svr_name='tmp'):\n",
    "    all_preds = []\n",
    "    train_df_f = train_df.copy()\n",
    "\n",
    "    for i in range(N_FOLDS): \n",
    "        learn = get_learner(fold_num=i,model_name=model_name,ifpretrained=ifpretrained,ifcut=ifcut)\n",
    "        learn.model_dir = ''\n",
    "        learn.load(model_path + f'{i}.pkl')\n",
    "        learn.model.head = nn.Identity()\n",
    "        dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n",
    "                            valid_pct=0.2, #80-20 train-validation random split\n",
    "                            seed=myseed, #seed\n",
    "                            fn_col='path', #filename/path is in the second column of t|he DataFrame\n",
    "                            label_col='norm_score', #label is in the first column of the DataFrame\n",
    "                            y_block=RegressionBlock, #The type of target\n",
    "                            bs=BATCH_SIZE, #pass in batch size\n",
    "                            num_workers=8,\n",
    "                            item_tfms=Resize(image_size), #pass in item_tfms\n",
    "                            batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(),RandomErasing(p=0.5, max_count=6)])) \n",
    "        train_dl = dls.test_dl(test_df)\n",
    "        embed, _ = learn.tta(dl=train_dl, n=n, beta=beta)\n",
    "        embed = embed.numpy()\n",
    "        clf = pickle.load(open(svr_name + f'{i}.pkl','rb'))\n",
    "#         if i in [0,1,2]:\n",
    "#             clf = pickle.load(open('../input/svrweight/svr_model_swin_large_384_vv1_' + f'{i}.pkl', \"rb\"))\n",
    "#         else:\n",
    "#             clf = pickle.load(open('../input/fork-of-fork-of-single-model-submit-083f3e/svr_model_swin_large_384_vv1_' + f'{i}.pkl', \"rb\"))\n",
    "        pred_clf = clf.predict(embed)\n",
    "        all_preds.append(pred_clf)\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    sample_df = pd.read_csv(dataset_path/'sample_submission.csv')\n",
    "    preds = np.mean(np.stack(all_preds), axis=0)\n",
    "    sample_df['Pawpularity'] = preds*100\n",
    "    return sample_df\n",
    "\n",
    "def test_cv_svr(model_name,ifpretrained,image_size,model_path,n,beta,N_FOLDS=5,ifcut=False,svr_name='tmp'):\n",
    "    all_preds = []\n",
    "    train_df_f = train_df.copy()\n",
    "    train_df_f['pred'] = 1\n",
    "    for i in range(N_FOLDS): \n",
    "        learn = get_learner(fold_num=i,model_name=model_name,ifpretrained=ifpretrained,ifcut=ifcut)\n",
    "        learn.model_dir = ''\n",
    "        learn.load(model_path + f'{i}.pkl')\n",
    "        learn.model.head = nn.Identity()\n",
    "        dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n",
    "                            valid_pct=0.2, #80-20 train-validation random split\n",
    "                            seed=myseed, #seed\n",
    "                            fn_col='path', #filename/path is in the second column of t|he DataFrame\n",
    "                            label_col='norm_score', #label is in the first column of the DataFrame\n",
    "                            y_block=RegressionBlock, #The type of target\n",
    "                            bs=BATCH_SIZE, #pass in batch size\n",
    "                            num_workers=8,\n",
    "                            item_tfms=Resize(image_size), #pass in item_tfms\n",
    "                            batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation(),RandomErasing(p=0.5, max_count=6)])) \n",
    "        train_dl = dls.test_dl(train_df[train_df['fold'] == i])\n",
    "        embed, _ = learn.tta(dl=train_dl, n=n, beta=beta)\n",
    "        embed = embed.numpy()\n",
    "        clf = pickle.load(open(svr_name + f'{i}.pkl','rb'))\n",
    "#         if i in [0,1,2]:\n",
    "#             clf = pickle.load(open('../input/svrweight/svr_model_swin_large_384_vv1_' + f'{i}.pkl', \"rb\"))\n",
    "#         else:\n",
    "#             clf = pickle.load(open('../input/fork-of-fork-of-single-model-submit-083f3e/svr_model_swin_large_384_vv1_' + f'{i}.pkl', \"rb\"))\n",
    "        pred_clf = clf.predict(embed)\n",
    "        all_preds.append(pred_clf)\n",
    "        print(f'Fold {i} results' , np.sqrt(((np.array(pred_clf)/100  - train_df[train_df['fold'] == i]['norm_score'])**2).mean()))\n",
    "        train_df_f.loc[train_df_f['fold'] == i,'pred'] = np.array(pred_clf)\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    print(np.sqrt(((train_df_f['pred']/100- train_df_f['norm_score']) ** 2).mean()))\n",
    "#     sample_df['Pawpularity'] = preds*100\n",
    "    return train_df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T14:49:01.278711Z",
     "iopub.status.busy": "2022-01-09T14:49:01.278445Z",
     "iopub.status.idle": "2022-01-09T14:49:01.281823Z",
     "shell.execute_reply": "2022-01-09T14:49:01.281146Z",
     "shell.execute_reply.started": "2022-01-09T14:49:01.278675Z"
    }
   },
   "outputs": [],
   "source": [
    "# cv_df1 = test_cv_svr('swin_large_patch4_window7_224',False,224,'../input/swin-ting-model-embed-fastai/models/model_fold_',1,1,5,False,'../input/svrweight/svr_model_swin_tiny_224_vv1_')\n",
    "# cv_df2 = test_cv('swin_large_patch4_window7_224',False,224,'../input/swin-ting-model-embed-fastai/models/model_fold_',1,1,train_df,5,False)\n",
    "# cv_df3 = test_cv('swin_large_patch4_window12_384_in22k',False,384,'../input/pet-finder-new-model/swin_large_22k_v3_',1,1,train_df,5,False)\n",
    "# cv_df4 = test_cv_svr('swin_large_patch4_window12_384_in22k',False,384,'../input/pet-finder-new-model/swin_large_22k_v3_',1,1,5,False,'../input/fork-of-fork-of-single-model-submit-083f3e/svr_model_swin_large_384_vv1_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T14:49:01.283822Z",
     "iopub.status.busy": "2022-01-09T14:49:01.283273Z",
     "iopub.status.idle": "2022-01-09T14:49:01.302864Z",
     "shell.execute_reply": "2022-01-09T14:49:01.302093Z",
     "shell.execute_reply.started": "2022-01-09T14:49:01.283786Z"
    }
   },
   "outputs": [],
   "source": [
    "# weight = [0.6 * 0.6 ,0.6 * 0.4 ,0.4 * 0.6 ,0.4 * 0.4]\n",
    "# pred = cv_df1['pred'] / 100 * weight[0] + cv_df2['pred']  * weight[1]  + cv_df3['pred']  * weight[2]  + cv_df4['pred'] / 100 * weight[3]\n",
    "# test_rmse(pred,cv_df1['norm_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T14:59:00.823518Z",
     "iopub.status.busy": "2022-01-09T14:59:00.822767Z",
     "iopub.status.idle": "2022-01-09T15:05:28.507668Z",
     "shell.execute_reply": "2022-01-09T15:05:28.506918Z",
     "shell.execute_reply.started": "2022-01-09T14:59:00.823476Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_df1 = get_submit('swin_large_patch4_window7_224',False,224,'../input/swin-ting-model-embed-fastai/models/model_fold_',5,0,5,False)\n",
    "sample_svr1 = get_submit_svr('swin_large_patch4_window7_224',False,224,'../input/swin-ting-model-embed-fastai/models/model_fold_',1,1,5,False,svr_name='../input/svrweight/svr_model_swin_tiny_224_vv1_')\n",
    "sample_df2 = get_submit('swin_large_patch4_window12_384_in22k',False,384,'../input/pet-finder-new-model/swin_large_22k_v3_',1,1,5,False)\n",
    "# sample_svr2 = get_submit_svr('swin_large_patch4_window12_384_in22k',False,384,'../input/pet-finder-new-model/swin_large_22k_v3_',1,1,5,False,svr_name='../input/fork-of-fork-of-single-model-submit-083f3e/svr_model_swin_large_384_vv1_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-09T14:57:20.796237Z",
     "iopub.status.idle": "2022-01-09T14:57:20.798034Z",
     "shell.execute_reply": "2022-01-09T14:57:20.797776Z",
     "shell.execute_reply.started": "2022-01-09T14:57:20.797747Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/tez-lib/\")\n",
    "sys.path.append(\"../input/timmmaster/\")\n",
    "\n",
    "import tez\n",
    "import albumentations\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from tez.callbacks import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "class args:\n",
    "    batch_size = 16\n",
    "    image_size = 384\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-09T14:57:20.799599Z",
     "iopub.status.idle": "2022-01-09T14:57:20.800371Z",
     "shell.execute_reply": "2022-01-09T14:57:20.800116Z",
     "shell.execute_reply.started": "2022-01-09T14:57:20.800087Z"
    }
   },
   "outputs": [],
   "source": [
    "class PawpularDataset:\n",
    "    def __init__(self, image_paths, dense_features, targets, augmentations):\n",
    "        self.image_paths = image_paths\n",
    "        self.dense_features = dense_features\n",
    "        self.targets = targets\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        image = cv2.imread(self.image_paths[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.augmentations is not None:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "            \n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        \n",
    "        features = self.dense_features[item, :]\n",
    "        targets = self.targets[item]\n",
    "        \n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"features\": torch.tensor(features, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.float),\n",
    "        }\n",
    "    \n",
    "class PawpularModel(tez.Model):\n",
    "    def __init__(self,pretrained=True):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            'swin_large_patch4_window12_384_in22k', pretrained=False, num_classes=0, in_chans=3\n",
    "        )\n",
    "        # self.backbone = timm.create_model(\n",
    "        #             'swin_tiny_patch4_window7_224', pretrained=True, num_classes=0, in_chans=3\n",
    "        #         )\n",
    "        num_features = self.backbone.num_features\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5), nn.Linear(num_features, 1)\n",
    "        )\n",
    "        self.step_scheduler_after = \"epoch\"\n",
    "\n",
    "    def monitor_metrics(self, outputs, targets):\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        targets = targets.cpu().detach().numpy()\n",
    "        rmse = metrics.mean_squared_error(targets, outputs, squared=False)\n",
    "        return {\"rmse\": rmse}\n",
    "\n",
    "    def fetch_scheduler(self):\n",
    "        # sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        #     self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n",
    "        # )\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            self.optimizer, T_0=20,  eta_min=1e-4\n",
    "        )\n",
    "        return sch\n",
    "\n",
    "    def fetch_optimizer(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=1e-5)\n",
    "        return opt\n",
    "\n",
    "    def forward(self, image, features, targets=None):\n",
    "        x1 = self.backbone(image)\n",
    "        x = self.fc(x1)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "#         if targets is not None:\n",
    "#             loss =   nn.BCEWithLogitsLoss()(x, (targets / 100).view(-1, 1)) \n",
    "#             metrics = self.monitor_metrics((torch.sigmoid(x)*100).view(1,-1)[0], targets)\n",
    "#             return x, loss, metrics\n",
    "        return x, 0, {}\n",
    "    \n",
    "\n",
    "test_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(args.image_size, args.image_size, p=1),\n",
    "        albumentations.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "        albumentations.RandomBrightnessContrast(p=0.5),\n",
    "        albumentations.augmentations.transforms.Cutout(num_holes=8, max_h_size=8, max_w_size=8, fill_value=0, always_apply=False, p=0.5),\n",
    "        # albumentations.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "        # albumentations.augmentations.geometric.rotate.RandomRotate90(p=0.5),\n",
    "        # albumentations.augmentations.transforms.VerticalFlip(p=0.5),\n",
    "        # albumentations.augmentations.transforms.Blur(blur_limit=7, always_apply=False, p=0.5),\n",
    "        # albumentations.augmentations.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "        # albumentations.augmentations.transforms.Downscale(scale_min=0.25, scale_max=0.25, interpolation=0, always_apply=False, p=0.5),\n",
    "        # albumentations.augmentations.transforms.GaussianBlur(blur_limit=(3, 7), sigma_limit=0, always_apply=False, p=0.5),\n",
    "        # albumentations.augmentations.transforms.HorizontalFlip(p=0.5),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-09T14:57:20.801769Z",
     "iopub.status.idle": "2022-01-09T14:57:20.802528Z",
     "shell.execute_reply": "2022-01-09T14:57:20.802196Z",
     "shell.execute_reply.started": "2022-01-09T14:57:20.802172Z"
    }
   },
   "outputs": [],
   "source": [
    "import cuml, pickle\n",
    "from cuml.svm import SVR\n",
    "print('RAPIDS version',cuml.__version__,'\\n')\n",
    "\n",
    "# LOAD_SVR_FROM_PATH = '../input/svr-models-10-folds/'\n",
    "LOAD_SVR_FROM_PATH = '../input/pet-finder-embedding/'\n",
    "df = pd.read_csv('../input/same-old-creating-folds/train_10folds.csv')\n",
    "print('Train shape:', df.shape )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-09T14:57:20.803844Z",
     "iopub.status.idle": "2022-01-09T14:57:20.804485Z",
     "shell.execute_reply": "2022-01-09T14:57:20.804273Z",
     "shell.execute_reply.started": "2022-01-09T14:57:20.804248Z"
    }
   },
   "outputs": [],
   "source": [
    "super_final_predictions = []\n",
    "super_final_predictions2 = []\n",
    "super_final_oof_predictions = []\n",
    "super_final_oof_predictions2 = []\n",
    "super_final_oof_true = []\n",
    "\n",
    "for fold_ in range(10):\n",
    "    print('#'*25)\n",
    "    print('### FOLD',fold_+1)\n",
    "    print('#'*25)\n",
    "    \n",
    "    model = PawpularModel()\n",
    "    model.load(f\"../input/cv-tez-model/swin_large_22kf{fold_}.bin\", device=\"cuda\", weights_only=True)\n",
    "\n",
    "    df_test = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\n",
    "    test_img_paths = [f\"../input/petfinder-pawpularity-score/test/{x}.jpg\" for x in df_test[\"Id\"].values]\n",
    "        \n",
    "    df_valid = df[df.kfold == fold_].reset_index(drop=True)#.iloc[:160]\n",
    "    valid_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_valid[\"Id\"].values]\n",
    "\n",
    "    dense_features = [\n",
    "        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n",
    "    ]\n",
    "    \n",
    "    name = f\"SVR_fold_{fold_}.pkl\" \n",
    "    if LOAD_SVR_FROM_PATH is None:\n",
    "        ##################\n",
    "        # EXTRACT TRAIN EMBEDDINGS\n",
    "        \n",
    "        df_train = df[df.kfold != fold_].reset_index(drop=True)#.iloc[:320]\n",
    "        train_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_train[\"Id\"].values]\n",
    "        \n",
    "        train_dataset = PawpularDataset(\n",
    "            image_paths=train_img_paths,\n",
    "            dense_features=df_train[dense_features].values,\n",
    "            targets=df_train['Pawpularity'].values/100.0,\n",
    "            augmentations=test_aug,\n",
    "        )\n",
    "        print('Extracting train embedding...')\n",
    "        train_predictions = model.predict(train_dataset, batch_size=2*args.batch_size, n_jobs=-1)\n",
    "    \n",
    "        embed = np.array([]).reshape((0,1536))\n",
    "        for preds in train_predictions:\n",
    "            embed = np.concatenate([embed,preds[:,1:]],axis=0)\n",
    "        \n",
    "        ##################\n",
    "        # FIT RAPIDS SVR\n",
    "        print('Fitting SVR...')\n",
    "        clf = SVR(C=20.0)\n",
    "        clf.fit(embed.astype('float32'), df_train.Pawpularity.values.astype('int32'))\n",
    "    \n",
    "        ##################\n",
    "        # SAVE RAPIDS SVR \n",
    "        pickle.dump(clf, open(name, \"wb\"))\n",
    "        \n",
    "    else:\n",
    "        ##################\n",
    "        # LOAD RAPIDS SVR \n",
    "        print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n",
    "        clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n",
    "\n",
    "    ##################\n",
    "    # TEST PREDICTIONS\n",
    "    test_dataset = PawpularDataset(\n",
    "        image_paths=test_img_paths,\n",
    "        dense_features=df_test[dense_features].values,\n",
    "        targets=np.ones(len(test_img_paths)),\n",
    "        augmentations=test_aug,\n",
    "    )\n",
    "    print('Predicting test...')\n",
    "    test_predictions = model.predict(test_dataset, batch_size=2*args.batch_size, n_jobs=-1)\n",
    "\n",
    "    final_test_predictions = []\n",
    "    embed = np.array([]).reshape((0,1536))\n",
    "    for preds in test_predictions: #tqdm\n",
    "        final_test_predictions.extend(preds[:,:1].ravel().tolist())\n",
    "        embed = np.concatenate([embed,preds[:,1:]],axis=0)\n",
    "\n",
    "    final_test_predictions = [sigmoid(x) * 100 for x in final_test_predictions]\n",
    "    final_test_predictions2 = clf.predict(embed)\n",
    "    super_final_predictions.append(final_test_predictions)\n",
    "    super_final_predictions2.append(final_test_predictions2)\n",
    "\n",
    "\n",
    "best_w = 0.5\n",
    "super_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\n",
    "super_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\n",
    "df_test[\"Pawpularity\"] = (1-best_w)*super_final_predictions + best_w*super_final_predictions2\n",
    "df_test = df_test[[\"Id\", \"Pawpularity\"]]\n",
    "# Compute CV Score\n",
    "# Below we compute the overall CV RSME scores of just the NN head, just the SVR head, and an ensemble of 50% NN and 50% SVR heads. Then we plot all ensemble weights to find the optimal weights for NN head and SVR heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-09T14:57:20.805876Z",
     "iopub.status.idle": "2022-01-09T14:57:20.806611Z",
     "shell.execute_reply": "2022-01-09T14:57:20.806366Z",
     "shell.execute_reply.started": "2022-01-09T14:57:20.806339Z"
    }
   },
   "outputs": [],
   "source": [
    "weight = [0.7 * 0.8  ,0.7 * 0.2 ,0 ,0.3]\n",
    "sample_df1['Pawpularity'] = weight[0] * sample_df1['Pawpularity'] + weight[1] * sample_svr1['Pawpularity']  / 100 + weight[2] * sample_df2['Pawpularity']  + weight[3] * df_test['Pawpularity']\n",
    "sample_df1.to_csv(\"submission.csv\", index=False)\n",
    "sample_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2684322,
     "sourceId": 25383,
     "sourceType": "competition"
    },
    {
     "datasetId": 1027206,
     "sourceId": 2694831,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1647480,
     "sourceId": 2704622,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1651637,
     "sourceId": 2738675,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 982170,
     "sourceId": 2792068,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1745837,
     "sourceId": 2866169,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1748431,
     "sourceId": 2977298,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1693911,
     "sourceId": 2982691,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1837719,
     "sourceId": 2999826,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1851397,
     "sourceId": 3023088,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1771368,
     "sourceId": 3023207,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1607245,
     "sourceId": 3030765,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 75466508,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 82180243,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 82699144,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 83187800,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 84324069,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 84367827,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 84367925,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30146,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
